{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import operator\n",
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get all the episodes' names in season.txt\n",
    "# It is like getting the total philosophers' names\n",
    "f1 = io.open('season.txt', 'r', encoding='utf-8')\n",
    "text = f1.read()\n",
    "episodesname = re.findall(r'\\[\\[(.*?)[\\|\\]\\]]', text)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the LabMT file which is the file containing the sentiment words and their score\n",
    "f1 = io.open('LabMT.txt', 'r' ,encoding='utf-8')\n",
    "wlist=f1.read().split()\n",
    "wordlist=wlist[15:len(wlist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment(textfile):\n",
    "    if not isinstance(textfile,list):\n",
    "        #Load the textfile that should be analyzed\n",
    "        text1 = io.open(textfile, 'r',encoding='utf-8')\n",
    "        textlist=text1.read().split()\n",
    "        text1.close()\n",
    "    else:\n",
    "        textlist=textfile\n",
    "    #Remove all numbers.\n",
    "    nonumbers=re.compile(\"[^\\d]+\").findall(' '.join(textlist))\n",
    "    #Remove everything that is not words and return their lowercase.\n",
    "    onlywords=re.compile(\"[\\w|']+\").findall(' '.join(nonumbers))\n",
    "    finallist=[w.lower() for w in onlywords]\n",
    "\n",
    "    #Make a list of all the words in the textfile and their count\n",
    "    counts = Counter(finallist)\n",
    "    most_common_list=counts.most_common()\n",
    "\n",
    "    #Set the score to 0 and the word count to 0.\n",
    "    score=0\n",
    "    wordcount=0\n",
    "    for i in range(len(most_common_list)):\n",
    "        #Get a word in the textfile that is being scored.\n",
    "        curword=most_common_list[i]\n",
    "        #If the list in the text is part of the sentiment wordlist do the following.\n",
    "        if curword[0] in wordlist:\n",
    "            #Find the index of the word in the wordlist\n",
    "            #and then add the score times the number of times the words appear to score\n",
    "            wordindex=wordlist.index(curword[0])\n",
    "            #The score is always 2 places further down in the list compared to the word.\n",
    "            if wordlist[wordindex+2]!='--':\n",
    "                score+=float(wordlist[wordindex+2])*curword[1]\n",
    "                wordcount+=curword[1]\n",
    "    if score==0:\n",
    "        if not isinstance(textfile,list):\n",
    "            print \"None of the words in %s was in the LabMT wordlist.\" %textfile\n",
    "        else:\n",
    "            print \"None of the words in the text file was in the LabMT wordlist.\"\n",
    "    else:\n",
    "        return score/wordcount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character sentiment score\n",
    "* Count the frequency of the characters in each episodes\n",
    "\n",
    "* If the character appears more than x times, calculate the sentiment score and give the score to the character\n",
    "\n",
    "* Store the score of each character and average them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----season 1-----\n",
      "-----season 2-----\n",
      "-----season 3-----\n",
      "-----season 4-----\n",
      "-----season 5-----\n",
      "-----season 6-----\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jhiqui', 5.3829896259037984),\n",
       " ('Wylla', 5.3829896259037984),\n",
       " ('Catspaw assassin', 5.3829896259037984),\n",
       " ('Lady', 5.3829896259037984),\n",
       " ('Lothar Frey', 5.3748657821660046),\n",
       " ('Prendahl na Ghezn', 5.3706265457543241),\n",
       " ('Mero', 5.3706265457543241),\n",
       " ('Pentoshi servant', 5.3638706256627726),\n",
       " ('Waymar Royce', 5.3638706256627726),\n",
       " ('Wildling girl', 5.3638706256627726)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charkeys=sentdict.keys()\n",
    "chardictmean={}\n",
    "for name in charkeys:\n",
    "    chardictmean[name]=np.mean(sentdict[name])\n",
    "    \n",
    "char_sent_sorted=sorted(chardictmean.items(), key=operator.itemgetter(1),reverse=True)\n",
    "char_sent_sorted[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* After we've done this, consider their sentiment score with attributes like their houses, dead/alive. See if a dead person has lower sentiment score, and/or compare the sentiment average score of different houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load directed graph, undirected graph and the list of philosophers.\n",
    "dg = nx.read_gpickle(\"Digraph_GOT_with_attributes.gpickle\")\n",
    "\n",
    "#Generate the largest connected component.\n",
    "subdg = list(nx.weakly_connected_component_subgraphs(dg))\n",
    "dg=subdg[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentiment of dead characters: 5.315106\n",
      "Mean sentiment of Alive characters: 5.313668\n"
     ]
    }
   ],
   "source": [
    "dead=[]\n",
    "alive=[]\n",
    "\n",
    "for name in sentdict.keys():\n",
    "    if nx.get_node_attributes(dg,\"Status\")[name]==\"Dead\":\n",
    "        dead.append(np.mean(sentdict[name]))\n",
    "    if nx.get_node_attributes(dg,\"Status\")[name]==\"Alive\":\n",
    "        alive.append(np.mean(sentdict[name]))\n",
    "\n",
    "print \"Mean sentiment of dead characters: %f\" % np.mean(dead)\n",
    "print \"Mean sentiment of Alive characters: %f\" % np.mean(alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allhouses=nx.get_node_attributes(dg,\"House\").values()\n",
    "unique_houses = list(set(x for l in allhouses for x in l))\n",
    "housesentdict={}\n",
    "\n",
    "for name in sentdict.keys():\n",
    "    for house in nx.get_node_attributes(dg,\"House\")[name]:\n",
    "        if house not in housesentdict.keys():\n",
    "            housesentdict[house]=[]\n",
    "        housesentdict[house].append(np.mean(sentdict[name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'Sansa Stark', 5.3829896259037984),\n",
       " (u'Illyrio Mopatis', 5.3638706256627726),\n",
       " (u'Dragonstone', 5.3602229617304502),\n",
       " (u'House Brune', 5.3602229617304502),\n",
       " (u'Second Sons (mercenary company)', 5.3580010187065659),\n",
       " (u'Xaro Xhoan Daxos', 5.353008964304145),\n",
       " (u'Craster', 5.348124481327801),\n",
       " (u'House Egen', 5.3415612595924786),\n",
       " (u'Khal', 5.3414816817853108),\n",
       " (u'House Payne', 5.3413611113208548)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housekeys=housesentdict.keys()\n",
    "housedictmean={}\n",
    "for name in housekeys:\n",
    "    housedictmean[name]=np.mean(housesentdict[name])\n",
    "    \n",
    "house_sent_sorted=sorted(housedictmean.items(), key=operator.itemgetter(1),reverse=True)\n",
    "house_sent_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
